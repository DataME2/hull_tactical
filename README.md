# Hull Tactical â€” Market Prediction (Kaggle)

> **Goal:** Design and deploy a daily S&P 500 forecasting + position-sizing strategy that maximizes the competitionâ€™s **modified Sharpe** metric while respecting **risk** and **runtime** constraints.

<p align="center">
  <img src="https://img.shields.io/badge/python-3.10+-blue" />
  <img src="https://img.shields.io/badge/lightgbm-optional-success" />
  <img src="https://img.shields.io/badge/license-MIT-green" />
  <img src="https://img.shields.io/badge/status-active-brightgreen" />
</p>

---

## ğŸ¯ Competition Objectives
1. **Forecast next-day S&P 500 return** (one prediction per trading day) with **calibrated uncertainty** (mean + std or quantiles).
2. **Maximize the competition score** via **risk-aware position sizing** while keeping **portfolio volatility â‰¤ 1.2Ã—** the S&P 500â€™s.
3. **Demonstrate out-of-sample robustness** using live-like **walkâ€‘forward, purged timeâ€‘series CV** across bull/bear/sideways regimes.

## ğŸ§® Scoring & Core Constraints (summarized)
- **Score:** \\\((\\text{Portfolio Return} - \\text{S&P 500 Return}) / \\max(\\text{Portfolio Vol}, 1.2\\times\\text{S&P 500 Vol})\\\)
- **Exposure bounds:** **0%â€“200%** (long-only leverage allowed for the competition).
- **Volatility cap:** **Portfolio volatility â‰¤ 120%** of S&P 500 volatility.
- **Risk guardrail:** soft **max drawdown â‰ˆ 20%** with automatic exposure throttling.
- **Turnover & costs:** model **5â€“10 bps** per trade to avoid alpha erosion.
- **Data hygiene:** **no lookâ€‘ahead**; respect `is_scored` windows and use **lagged** forward returns for testing.
- **Runtime:** packaged inference should complete within the evaluation time budget (â‰¤ ~9h), be **deterministic** and **stateful**.

> â„¹ï¸ Always consult the official Kaggle rules/overview for the exact, most current definitions and APIs.

---

## ğŸ—‚ï¸ Repository Structure
```
.
â”œâ”€ notebooks/
â”‚  â”œâ”€ 00_data_audit.ipynb
â”‚  â”œâ”€ 10_feature_engineering.ipynb
â”‚  â””â”€ 20_model_dev_walkforward.ipynb
â”œâ”€ src/
â”‚  â”œâ”€ data/
â”‚  â”‚  â”œâ”€ loader.py          # Calendar alignment, missing-data policy (FFILL/interp)
â”‚  â”‚  â””â”€ leak_checks.py     # Strict lagging and feature availability at t
â”‚  â”œâ”€ features/
â”‚  â”‚  â”œâ”€ momentum.py        # 1â€“60d returns, rolling means, RSI, etc.
â”‚  â”‚  â”œâ”€ volatility.py      # Realized vol, park vol, ATR-like stats
â”‚  â”‚  â””â”€ macro_sentiment.py # Rates, spreads, macro cycles, news/sentiment
â”‚  â”œâ”€ models/
â”‚  â”‚  â”œâ”€ baseline.py        # Ridge/ElasticNet or LightGBM baseline
â”‚  â”‚  â””â”€ ensemble.py        # Optional: stacking / regime-switching
â”‚  â”œâ”€ sizing/
â”‚  â”‚  â”œâ”€ vol_target.py      # Exposure âˆ target_vol / predicted_vol
â”‚  â”‚  â””â”€ drawdown_brake.py  # Exposure throttle on MDD
â”‚  â”œâ”€ evaluation/
â”‚  â”‚  â”œâ”€ scoring.py         # Competition metric + turnover/costs
â”‚  â”‚  â””â”€ walkforward.py     # Purged walk-forward CV splits
â”‚  â”œâ”€ runtime/
â”‚  â”‚  â”œâ”€ inference.py       # Deterministic, stateful prediction entrypoint
â”‚  â”‚  â””â”€ state.py           # Save/restore model state across calls
â”‚  â””â”€ utils/
â”‚     â”œâ”€ config.py
â”‚     â””â”€ logging.py
â”œâ”€ configs/
â”‚  â”œâ”€ baseline.yaml         # Features, model, CV, sizing knobs
â”‚  â””â”€ prod.yaml             # Frozen parameters for final runs
â”œâ”€ tests/
â”‚  â””â”€ test_scoring.py
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â””â”€ README.md
```

---

## âš¡ Quickstart

### 1) Environment
```bash
# create env
python -m venv .venv
source .venv/bin/activate       # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Data
Download competition data from Kaggle and place under `./input/` (preserving original filenames).  
This repo assumes a layout like:
```
input/
â”œâ”€ train.parquet
â”œâ”€ test.parquet
â”œâ”€ example_test_files/...
â””â”€ supplemental/...
```

### 3) Baseline training (local)
```bash
python -m src.data.loader --check          # sanity checks + leakage tests
python -m src.models.baseline --config configs/baseline.yaml
python -m src.evaluation.walkforward --config configs/baseline.yaml
```

### 4) Inference (packaged, deterministic)
```bash
python -m src.runtime.inference --config configs/prod.yaml --save-state out/state/
```

---

## ğŸ§  Modeling Approach (MVP â†’ Pro)
- **Signals:** trend (10â€“60d), shortâ€‘term reversal (1â€“5d), volatility clustering, macro & rates proxies, and sentiment features.
- **Learners:** start with **Ridge/ElasticNet** or **LightGBM**; optionally add **stacking** or **regime switching** (e.g., HMM/thresholds).
- **Uncertainty:** output mean + predictive std (or quantiles) to drive **vol-targeted sizing**.
- **Sizer:** `position_t = clip(signal_t * target_vol / predicted_vol_t, 0, 2)` with a **small Kelly fraction** & **drawdown brake**.
- **Costs:** include `bps_per_trade` and **turnover penalties** in objective and reports.

## ğŸ§ª Validation
- **Walkâ€‘forward, purged splits** with ~3â€‘month **gaps**; â‰¥2â€‘year warmâ€‘up window.
- **Diagnostics:** rolling Sharpe, hitâ€‘rate, MDD, turnover/cost impact, regime buckets.
- **Leakage protection:** enforce timeâ€‘correct lags and feature availability checks at time *t*.

---

## ğŸ“ˆ Reporting
- `reports/` folder stores:
  - Rolling metrics (Sharpe, hit rate, drawdown)
  - Exposure, turnover, and cost curves
  - Regimeâ€‘sliced performance tables
- `src/evaluation/scoring.py` mirrors the competition metric for applesâ€‘toâ€‘apples comparisons.

---

## ğŸ” Reproducibility & Runtime
- Set a **global seed**; prefer deterministic algorithms and fixed thread counts.
- Package the inference path to run within the evaluation time budget (avoid slow external deps).
- Persist model **state** between calls (`src/runtime/state.py`).

---

## ğŸ—ºï¸ Roadmap
- [ ] Add macro & sentiment enrichments
- [ ] Calibrated quantile models
- [ ] Regime detector + adaptive ensembling
- [ ] Turnoverâ€‘aware hyperparameter search
- [ ] Experiment tracking (MLflow/W&B) + artifacts

---

## ğŸ¤ Contributing
PRs are welcome! Please:
1. Open an issue describing the change.
2. Include tests for scoring/splits where relevant.
3. Keep configs reproducible and document new knobs.

---

## ğŸ“ License
This project is licensed under the **MIT License** (see `LICENSE`).

## ğŸ™ Acknowledgments
- Kaggle â€” Hull Tactical Market Prediction
- Community discussions on timeâ€‘series CV, leakage prevention, and riskâ€‘aware sizing.
